#!/usr/bin/env python3
"""
Detectionë§Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
Streamlit ì—†ì´ OpenCVë¡œ ë¹ ë¥´ê²Œ í™•ì¸
"""

import sys
import time
from pathlib import Path

import cv2

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.tracking.detector_configs import get_config
from src.tracking.yolox_detector import YOLOXDetector


def test_detection_on_video(video_path: str):
    """ë¹„ë””ì˜¤ì—ì„œ detection í…ŒìŠ¤íŠ¸"""

    print("ğŸ¯ Detection í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    # 1. YOLOXDetector ì´ˆê¸°í™”
    print("ğŸ“¡ YOLOX Detector ì´ˆê¸°í™” ì¤‘...")
    try:
        # crowded_scene ì„¤ì • ì‚¬ìš©
        config = get_config("crowded_scene")
        detector = YOLOXDetector(
            model_name=config.model_name,
            confidence_threshold=config.confidence_threshold,
            enable_image_enhancement=True,  # ì´ë¯¸ì§€ í–¥ìƒ í™œì„±í™”
            nms_iou_threshold=0.3,
        )
        print(
            f"âœ… Detector ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {config.model_name}, ì„ê³„ê°’: {config.confidence_threshold}"
        )
    except Exception as e:
        print(f"âŒ Detector ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # 2. ë¹„ë””ì˜¤ ì—´ê¸°
    print(f"ğŸ“¹ ë¹„ë””ì˜¤ ì—´ê¸°: {video_path}")
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps}fps, {frame_count}í”„ë ˆì„")

    # 3. í”„ë ˆì„ë³„ detection í…ŒìŠ¤íŠ¸
    frame_num = 0
    total_detections = 0
    start_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_num += 1

        # ë§¤ 10ë²ˆì§¸ í”„ë ˆì„ë§Œ ì²˜ë¦¬ (ì†ë„ í–¥ìƒ)
        if frame_num % 10 != 0:
            continue

        print(f"\nğŸ” í”„ë ˆì„ {frame_num} ì²˜ë¦¬ ì¤‘...")

        # Detection ìˆ˜í–‰
        detection_start = time.time()
        detections = detector.detect_objects(frame)
        detection_time = time.time() - detection_start

        print(f"â±ï¸  Detection ì‹œê°„: {detection_time:.3f}ì´ˆ")
        print(f"ğŸ‘ï¸  ê°ì§€ëœ ê°ì²´ ìˆ˜: {len(detections)}")

        # ê°ì§€ëœ ê°ì²´ ì •ë³´ ì¶œë ¥
        for i, det in enumerate(detections):
            print(
                f"   {i+1}. ID: {det.track_id}, í´ë˜ìŠ¤: {det.class_name}, "
                f"ì‹ ë¢°ë„: {det.confidence:.3f}, ë°”ìš´ë”©ë°•ìŠ¤: {det.bbox}"
            )

        total_detections += len(detections)

        # ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
        annotated_frame = frame.copy()
        for det in detections:
            x, y, w, h = det.bbox
            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # ë¼ë²¨ í‘œì‹œ
            label = f"{det.class_name}: {det.confidence:.2f}"
            cv2.putText(
                annotated_frame,
                label,
                (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (0, 255, 0),
                2,
            )

        # ì •ë³´ í‘œì‹œ
        info_text = f"Frame: {frame_num}, Detections: {len(detections)}, Time: {detection_time:.3f}s"
        cv2.putText(
            annotated_frame,
            info_text,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )

        # í™”ë©´ì— í‘œì‹œ
        cv2.imshow("Detection Test", annotated_frame)

        # ESC í‚¤ë¡œ ì¢…ë£Œ
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
            break

        # ì²˜ìŒ 50í”„ë ˆì„ë§Œ ì²˜ë¦¬ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
        if frame_num >= 50:
            print(f"\nâ¹ï¸  í…ŒìŠ¤íŠ¸ ì™„ë£Œ (50í”„ë ˆì„ ì²˜ë¦¬)")
            break

    # ê²°ê³¼ ìš”ì•½
    elapsed_time = time.time() - start_time
    avg_detections = total_detections / (frame_num // 10) if frame_num > 0 else 0

    print(f"\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   ì²˜ë¦¬ëœ í”„ë ˆì„: {frame_num // 10}")
    print(f"   ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
    print(f"   í‰ê·  ì´ˆë‹¹ í”„ë ˆì„: {(frame_num // 10) / elapsed_time:.2f} FPS")
    print(f"   ì´ ê°ì§€ ê°ì²´: {total_detections}")
    print(f"   í‰ê·  í”„ë ˆì„ë‹¹ ê°ì§€: {avg_detections:.1f}ê°œ")

    cap.release()
    cv2.destroyAllWindows()


def test_detection_on_image(image_path: str):
    """ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ detection í…ŒìŠ¤íŠ¸"""

    print("ğŸ–¼ï¸  ë‹¨ì¼ ì´ë¯¸ì§€ Detection í…ŒìŠ¤íŠ¸...")

    # YOLOXDetector ì´ˆê¸°í™”
    config = get_config("crowded_scene")
    detector = YOLOXDetector(
        model_name=config.model_name,
        confidence_threshold=config.confidence_threshold,
        enable_image_enhancement=True,
    )

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    print(f"ğŸ“Š ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")

    # Detection ìˆ˜í–‰
    start_time = time.time()
    detections = detector.detect_objects(image)
    detection_time = time.time() - start_time

    print(f"â±ï¸  Detection ì‹œê°„: {detection_time:.3f}ì´ˆ")
    print(f"ğŸ‘ï¸  ê°ì§€ëœ ê°ì²´ ìˆ˜: {len(detections)}")

    # ê²°ê³¼ í‘œì‹œ
    for i, det in enumerate(detections):
        print(
            f"   {i+1}. í´ë˜ìŠ¤: {det.class_name}, ì‹ ë¢°ë„: {det.confidence:.3f}, ë°”ìš´ë”©ë°•ìŠ¤: {det.bbox}"
        )

    # ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
    result_image = image.copy()
    for det in detections:
        x, y, w, h = det.bbox
        cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)

        label = f"{det.class_name}: {det.confidence:.2f}"
        cv2.putText(
            result_image,
            label,
            (x, y - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 255, 0),
            2,
        )

    # ê²°ê³¼ ì €ì¥ ë° í‘œì‹œ
    output_path = "detection_result.jpg"
    cv2.imwrite(output_path, result_image)
    print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")

    cv2.imshow("Detection Result", result_image)
    print("ğŸ–±ï¸  ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œ...")
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    print("ğŸš€ YOLOX Detection í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    # ì‚¬ìš©ì ì…ë ¥
    test_type = input("í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ (1: ë¹„ë””ì˜¤, 2: ì´ë¯¸ì§€): ").strip()

    if test_type == "1":
        video_path = input("ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì…ë ¥: ").strip()
        if video_path and Path(video_path).exists():
            test_detection_on_video(video_path)
        else:
            print("âŒ ìœ íš¨í•œ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")

    elif test_type == "2":
        image_path = input("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥: ").strip()
        if image_path and Path(image_path).exists():
            test_detection_on_image(image_path)
        else:
            print("âŒ ìœ íš¨í•œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    else:
        print("âŒ ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš” (1 ë˜ëŠ” 2)")

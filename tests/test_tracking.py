#!/usr/bin/env python3
"""
OC-SORT ì¶”ì  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - data/people.mp4 ì‚¬ìš©
ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œ ID íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸
"""

import sys
import time
from pathlib import Path

import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.tracking.detector_configs import get_config
from src.tracking.engine import ObjectTracker


def test_tracking_on_video_frames(
    video_path: str, frame_indices=[50, 100, 150, 200, 250]
):
    """ë¹„ë””ì˜¤ íŠ¹ì • í”„ë ˆì„ë“¤ì—ì„œ tracking í…ŒìŠ¤íŠ¸"""

    print(f"ğŸ¬ ë¹„ë””ì˜¤ ì¶”ì  í…ŒìŠ¤íŠ¸: {video_path}")
    print("=" * 60)

    # ë¹„ë””ì˜¤ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps:.1f}fps, ì´ {frame_count}í”„ë ˆì„")

    # Tracker ì´ˆê¸°í™” (crowded_scene ì„¤ì • ì‚¬ìš©)
    config = get_config("crowded_scene")
    tracker = ObjectTracker(
        det_thresh=0.25,  # 0.6 -> 0.25ë¡œ ë‚®ì¶¤ (ë” ë§ì€ detection í—ˆìš©)
        max_age=30,  # ìµœëŒ€ ì¶”ì  ìœ ì§€ í”„ë ˆì„
        min_hits=3,  # ì¶”ì  ì‹œì‘ ìµœì†Œ hit ìˆ˜
        iou_threshold=0.3,  # IoU threshold for association
        delta_t=3,  # velocity calculation delta
        asso_func="iou",  # association function
        inertia=0.2,  # velocity inertia
        use_byte=False,  # ByteTrack association
        detector_config=config,  # detector config
        enable_image_enhancement=False,
        nms_iou_threshold=0.3,
    )

    print(
        f"ğŸ¯ Tracker ì´ˆê¸°í™”: {config.model_name}, ê²€ì¶œì„ê³„ê°’: {config.confidence_threshold}, ì¶”ì ì„ê³„ê°’: 0.25"
    )

    # temp ë””ë ‰í† ë¦¬ ìƒì„±
    Path("temp").mkdir(exist_ok=True)

    # ê° í”„ë ˆì„ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
    for frame_idx in frame_indices:
        if frame_idx >= frame_count:
            print(f"âš ï¸  í”„ë ˆì„ {frame_idx}ëŠ” ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨ (ìµœëŒ€: {frame_count})")
            continue

        print(f"\nğŸ” í”„ë ˆì„ {frame_idx} ì¶”ì  í…ŒìŠ¤íŠ¸...")

        # íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()

        if not ret:
            print(f"âŒ í”„ë ˆì„ {frame_idx}ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            continue

        print(f"ğŸ“ í”„ë ˆì„ í¬ê¸°: {frame.shape}")

        # Detection + Tracking ìˆ˜í–‰
        start_time = time.time()
        tracking_frame = tracker.track_frame(frame)
        tracking_time = time.time() - start_time

        print(f"â±ï¸  Tracking ì‹œê°„: {tracking_time:.3f}ì´ˆ")
        print(f"ğŸ‘ï¸  ì¶”ì ëœ ê°ì²´ ìˆ˜: {len(tracking_frame.detections)}")

        # ì‹ ë¢°ë„ë³„ ë¶„ë¥˜
        high_conf = [d for d in tracking_frame.detections if d.confidence >= 0.7]
        medium_conf = [
            d for d in tracking_frame.detections if 0.4 <= d.confidence < 0.7
        ]
        low_conf = [d for d in tracking_frame.detections if d.confidence < 0.4]

        print(
            f"ğŸ“Š ì‹ ë¢°ë„ë³„ ë¶„ë¥˜: ë†’ìŒ({len(high_conf)}) ì¤‘ê°„({len(medium_conf)}) ë‚®ìŒ({len(low_conf)})"
        )

        # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ì²´í¬
        img_h, img_w = frame.shape[:2]
        valid_count = 0
        invalid_count = 0

        for det in tracking_frame.detections:
            x, y, w, h = det.bbox
            if (
                x >= 0
                and y >= 0
                and x + w <= img_w
                and y + h <= img_h
                and w > 0
                and h > 0
            ):
                valid_count += 1
            else:
                invalid_count += 1

        print(f"ğŸ” ë°”ìš´ë”© ë°•ìŠ¤: ìœ íš¨({valid_count}) ë¬´íš¨({invalid_count})")

        # Track ID ë¶„ì„
        track_ids = [
            det.track_id
            for det in tracking_frame.detections
            if hasattr(det, "track_id") and det.track_id > 0
        ]
        unique_ids = set(track_ids)
        print(
            f"ğŸ†” Track ID ë¶„ì„: ì´ {len(unique_ids)}ê°œ ê³ ìœ  ID - {sorted(unique_ids)}"
        )

        # ì¶”ì  ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 10ê°œ)
        detections_sorted = sorted(
            tracking_frame.detections, key=lambda x: x.confidence, reverse=True
        )
        print("ğŸ“‹ ìƒìœ„ 10ê°œ ì¶”ì  ê²°ê³¼:")
        for i, det in enumerate(detections_sorted[:10]):
            track_id = getattr(det, "track_id", "N/A")
            print(
                f"   {i+1:2d}. ID={track_id:3}, ì‹ ë¢°ë„: {det.confidence:.3f}, í¬ê¸°: {det.bbox[2]:3d}x{det.bbox[3]:3d}, ìœ„ì¹˜: ({det.bbox[0]:4d}, {det.bbox[1]:4d})"
            )

        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        annotated_frame = frame.copy()
        drawn_count = 0

        for det in tracking_frame.detections:
            x, y, w, h = det.bbox
            track_id = getattr(det, "track_id", -1)

            # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ì²´í¬
            if x < 0 or y < 0 or x + w > img_w or y + h > img_h:
                continue

            # Track IDì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            if track_id > 0:
                # Track IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ìƒ‰ìƒ ìƒì„±
                np.random.seed(track_id)
                color = tuple(map(int, np.random.randint(0, 255, 3)))
                thickness = 3
            else:
                color = (128, 128, 128)  # íšŒìƒ‰ - ID ì—†ìŒ
                thickness = 1

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, thickness)
            drawn_count += 1

            # Track IDì™€ ì‹ ë¢°ë„ ë¼ë²¨
            if track_id > 0:
                label = f"ID{track_id}: {det.confidence:.2f}"
            else:
                label = f"?: {det.confidence:.2f}"

            # ë¼ë²¨ ë°°ê²½ê³¼ í…ìŠ¤íŠ¸
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            cv2.rectangle(
                annotated_frame, (x, y - 20), (x + label_size[0], y), color, -1
            )
            cv2.putText(
                annotated_frame,
                label,
                (x, y - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

        print(f"âœ… ì‹¤ì œë¡œ ê·¸ë ¤ì§„ ë°”ìš´ë”© ë°•ìŠ¤: {drawn_count}ê°œ")

        # ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        info_texts = [
            f"Frame {frame_idx}: Tracking Test",
            f"Total tracks: {len(tracking_frame.detections)}",
            f"Valid boxes: {valid_count}",
            f"Unique IDs: {len(unique_ids)}",
            f"High conf: {len(high_conf)}",
            f"Time: {tracking_time:.3f}s",
        ]

        for i, text in enumerate(info_texts):
            cv2.putText(
                annotated_frame,
                text,
                (10, 25 + i * 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
                cv2.LINE_AA,
            )

        # ê²°ê³¼ ì €ì¥
        output_path = f"temp/tracking_frame_{frame_idx}_result.jpg"
        cv2.imwrite(output_path, annotated_frame)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    cap.release()
    print("\nâœ… í”„ë ˆì„ë³„ ì¶”ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def test_continuous_tracking(video_path: str, start_frame=100, num_frames=50):
    """ì—°ì† í”„ë ˆì„ì—ì„œ tracking í…ŒìŠ¤íŠ¸ - ID ì¼ê´€ì„± í™•ì¸"""

    print(f"\nğŸ”„ ì—°ì† ì¶”ì  í…ŒìŠ¤íŠ¸ (í”„ë ˆì„ {start_frame}~{start_frame+num_frames-1})")
    print("=" * 60)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    # Tracker ì´ˆê¸°í™”
    config = get_config("crowded_scene")
    tracker = ObjectTracker(
        det_thresh=0.25,  # 0.6 -> 0.25ë¡œ ë‚®ì¶¤
        max_age=10,  # ë” ì§§ì€ max_ageë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        min_hits=2,  # ë” ë¹ ë¥¸ íŠ¸ë™ ìƒì„±
        iou_threshold=0.3,
        detector_config=config,
        enable_image_enhancement=False,
    )

    # ì‹œì‘ í”„ë ˆì„ìœ¼ë¡œ ì´ë™
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    # ID ì¶”ì  í†µê³„
    id_history = {}  # track_id: [frame_numbers]
    frame_stats = []

    print("ğŸ“¹ ì—°ì† í”„ë ˆì„ ì¶”ì  ì‹œì‘...")

    for i in range(num_frames):
        current_frame = start_frame + i
        ret, frame = cap.read()
        if not ret:
            break

        # Tracking ìˆ˜í–‰
        tracking_frame = tracker.track_frame(frame)

        # Track ID ê¸°ë¡
        current_ids = set()
        for det in tracking_frame.detections:
            track_id = getattr(det, "track_id", -1)
            if track_id > 0:
                current_ids.add(track_id)
                if track_id not in id_history:
                    id_history[track_id] = []
                id_history[track_id].append(current_frame)

        # í”„ë ˆì„ë³„ í†µê³„
        frame_stats.append(
            {
                "frame": current_frame,
                "total_tracks": len(tracking_frame.detections),
                "valid_ids": len(current_ids),
                "ids": sorted(current_ids),
            }
        )

        # 10í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥
        if i % 10 == 0 or i < 5:
            print(
                f"   í”„ë ˆì„ {current_frame}: {len(tracking_frame.detections)}ê°œ ì¶”ì , ID: {sorted(current_ids)}"
            )

    cap.release()

    # ID ì¶”ì  ë¶„ì„ ê²°ê³¼
    print("\nğŸ“Š ì—°ì† ì¶”ì  ë¶„ì„ ê²°ê³¼:")
    print(f"   ì²˜ë¦¬ëœ í”„ë ˆì„: {len(frame_stats)}")
    print(f"   ì´ ê³ ìœ  ID ìˆ˜: {len(id_history)}")

    # IDë³„ ì§€ì†ì„± ë¶„ì„
    print("\nğŸ†” IDë³„ ì¶”ì  ì§€ì†ì„±:")
    for track_id, frames in sorted(id_history.items()):
        duration = len(frames)
        first_frame = frames[0]
        last_frame = frames[-1]
        print(
            f"   ID {track_id:2d}: {duration:2d}í”„ë ˆì„ ì§€ì† (í”„ë ˆì„ {first_frame}~{last_frame})"
        )

    # í‰ê·  í†µê³„
    avg_tracks = sum(stat["total_tracks"] for stat in frame_stats) / len(frame_stats)
    avg_valid_ids = sum(stat["valid_ids"] for stat in frame_stats) / len(frame_stats)

    print("\nğŸ“ˆ í‰ê·  í†µê³„:")
    print(f"   í‰ê·  ì¶”ì  ê°ì²´ ìˆ˜: {avg_tracks:.1f}ê°œ")
    print(f"   í‰ê·  ìœ íš¨ ID ìˆ˜: {avg_valid_ids:.1f}ê°œ")


if __name__ == "__main__":
    video_path = "data/people.mp4"

    if not Path(video_path).exists():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        print("ğŸ“ data ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤:")
        for f in Path("data").glob("*.mp4"):
            print(f"   {f}")
        exit(1)

    print("ğŸš€ OC-SORT ì¶”ì  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    # temp ë””ë ‰í† ë¦¬ ìƒì„±
    Path("temp").mkdir(exist_ok=True)

    # 1. íŠ¹ì • í”„ë ˆì„ë“¤ì—ì„œ ì¶”ì  í…ŒìŠ¤íŠ¸
    test_tracking_on_video_frames(video_path, [50, 100, 150, 200, 287])

    print("\n" + "=" * 50)

    # 2. ì—°ì† í”„ë ˆì„ì—ì„œ ID ì¼ê´€ì„± í…ŒìŠ¤íŠ¸
    test_continuous_tracking(video_path, start_frame=100, num_frames=30)

    print("\nğŸ¯ ê²°ë¡ :")
    print("1. temp/tracking_frame_*.jpg íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”")
    print("2. ê° IDë³„ë¡œ ê³ ìœ í•œ ìƒ‰ìƒìœ¼ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§‘ë‹ˆë‹¤")
    print("3. ì—°ì† í”„ë ˆì„ì—ì„œ ID ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    print("4. ì¶”ì  ì§€ì†ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì„¸ìš”")

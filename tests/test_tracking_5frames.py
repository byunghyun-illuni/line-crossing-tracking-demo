#!/usr/bin/env python3
"""
OC-SORT ì¶”ì  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - 5í”„ë ˆì„ ì—°ì† í…ŒìŠ¤íŠ¸
ì‹¤ì œ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œ ID íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸ (ì—°ì† 5í”„ë ˆì„: 50-54)
"""

import sys
import time
from pathlib import Path

import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.tracking.detector_configs import get_config
from src.tracking.engine import ObjectTracker


def test_tracking_on_video_frames(video_path: str, frame_indices=[50, 51, 52, 53, 54]):
    """ë¹„ë””ì˜¤ íŠ¹ì • í”„ë ˆì„ë“¤ì—ì„œ tracking í…ŒìŠ¤íŠ¸"""

    print(f"ğŸ¬ ë¹„ë””ì˜¤ ì¶”ì  í…ŒìŠ¤íŠ¸: {video_path}")
    print("=" * 60)

    # ë¹„ë””ì˜¤ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps:.1f}fps, ì´ {frame_count}í”„ë ˆì„")

    # Tracker ì´ˆê¸°í™” (crowded_scene ì„¤ì • ì‚¬ìš©)
    config = get_config("crowded_scene")
    tracker = ObjectTracker(
        det_thresh=0.1,  # OCSort ë‚´ë¶€ í•„í„°ë§ì„ ê±°ì˜ ë¹„í™œì„±í™”
        max_age=30,
        min_hits=1,
        iou_threshold=0.3,
        delta_t=3,
        asso_func="iou",
        inertia=0.2,
        use_byte=True,
        detector_config=config,
        enable_image_enhancement=False,
        nms_iou_threshold=0.3,
    )

    print(
        f"ğŸ¯ Tracker ì´ˆê¸°í™”: {config.model_name}, ê²€ì¶œì„ê³„ê°’: {config.confidence_threshold}, ì¶”ì ì„ê³„ê°’: 0.1"
    )

    # temp ë””ë ‰í† ë¦¬ ìƒì„±
    Path("temp").mkdir(exist_ok=True)

    # ê° í”„ë ˆì„ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
    for frame_idx in frame_indices:
        if frame_idx >= frame_count:
            print(f"âš ï¸  í”„ë ˆì„ {frame_idx}ëŠ” ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨ (ìµœëŒ€: {frame_count})")
            continue

        print(f"\nğŸ” í”„ë ˆì„ {frame_idx} ì¶”ì  í…ŒìŠ¤íŠ¸...")

        # íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()

        if not ret:
            print(f"âŒ í”„ë ˆì„ {frame_idx}ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            continue

        print(f"ğŸ“ í”„ë ˆì„ í¬ê¸°: {frame.shape}")

        # Detection + Tracking ìˆ˜í–‰
        start_time = time.time()
        tracking_frame = tracker.track_frame(frame)
        tracking_time = time.time() - start_time

        print(f"â±ï¸  Tracking ì‹œê°„: {tracking_time:.3f}ì´ˆ")
        print(f"ğŸ‘ï¸  ì¶”ì ëœ ê°ì²´ ìˆ˜: {len(tracking_frame.detections)}")

        # ì‹ ë¢°ë„ë³„ ë¶„ë¥˜
        high_conf = [d for d in tracking_frame.detections if d.confidence >= 0.7]
        medium_conf = [
            d for d in tracking_frame.detections if 0.4 <= d.confidence < 0.7
        ]
        low_conf = [d for d in tracking_frame.detections if d.confidence < 0.4]

        print(
            f"ğŸ“Š ì‹ ë¢°ë„ë³„ ë¶„ë¥˜: ë†’ìŒ({len(high_conf)}) ì¤‘ê°„({len(medium_conf)}) ë‚®ìŒ({len(low_conf)})"
        )

        # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ì²´í¬
        img_h, img_w = frame.shape[:2]
        valid_count = 0
        invalid_count = 0

        for det in tracking_frame.detections:
            x, y, w, h = det.bbox
            if (
                x >= 0
                and y >= 0
                and x + w <= img_w
                and y + h <= img_h
                and w > 0
                and h > 0
            ):
                valid_count += 1
            else:
                invalid_count += 1

        print(f"ğŸ” ë°”ìš´ë”© ë°•ìŠ¤: ìœ íš¨({valid_count}) ë¬´íš¨({invalid_count})")

        # Track ID ë¶„ì„
        track_ids = [
            det.track_id
            for det in tracking_frame.detections
            if hasattr(det, "track_id") and det.track_id > 0
        ]
        unique_ids = set(track_ids)
        print(
            f"ğŸ†” Track ID ë¶„ì„: ì´ {len(unique_ids)}ê°œ ê³ ìœ  ID - {sorted(unique_ids)}"
        )

        # ì¶”ì  ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 10ê°œ)
        detections_sorted = sorted(
            tracking_frame.detections, key=lambda x: x.confidence, reverse=True
        )
        print("ğŸ“‹ ìƒìœ„ 10ê°œ ì¶”ì  ê²°ê³¼:")
        for i, det in enumerate(detections_sorted[:10]):
            track_id = getattr(det, "track_id", "N/A")
            print(
                f"   {i+1:2d}. ID={track_id:3}, ì‹ ë¢°ë„: {det.confidence:.3f}, í¬ê¸°: {det.bbox[2]:3d}x{det.bbox[3]:3d}, ìœ„ì¹˜: ({det.bbox[0]:4d}, {det.bbox[1]:4d})"
            )

        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        annotated_frame = frame.copy()
        drawn_count = 0

        for det in tracking_frame.detections:
            x, y, w, h = det.bbox
            track_id = getattr(det, "track_id", -1)

            # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ì²´í¬
            if x < 0 or y < 0 or x + w > img_w or y + h > img_h:
                continue

            # Track IDì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            if track_id > 0:
                # Track IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ìƒ‰ìƒ ìƒì„±
                np.random.seed(track_id)
                color = tuple(map(int, np.random.randint(0, 255, 3)))
                thickness = 3
                label = f"ID{track_id}: {det.confidence:.2f}"
            else:
                color = (128, 128, 128)  # íšŒìƒ‰ - ID ì—†ìŒ
                thickness = 1
                label = f"?: {det.confidence:.2f}"

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, thickness)
            drawn_count += 1

            # ë¼ë²¨ ë°°ê²½ê³¼ í…ìŠ¤íŠ¸
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            cv2.rectangle(
                annotated_frame, (x, y - 20), (x + label_size[0], y), color, -1
            )
            cv2.putText(
                annotated_frame,
                label,
                (x, y - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

        print(f"âœ… ì‹¤ì œë¡œ ê·¸ë ¤ì§„ ë°”ìš´ë”© ë°•ìŠ¤: {drawn_count}ê°œ")

        # ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        info_texts = [
            f"Frame {frame_idx}: Tracking Test",
            f"Total tracks: {len(tracking_frame.detections)}",
            f"Valid boxes: {valid_count}",
            f"Unique IDs: {len(unique_ids)}",
            f"High conf: {len(high_conf)}",
            f"Time: {tracking_time:.3f}s",
        ]

        for i, text in enumerate(info_texts):
            cv2.putText(
                annotated_frame,
                text,
                (10, 25 + i * 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
                cv2.LINE_AA,
            )

        # ê²°ê³¼ ì €ì¥
        output_path = f"temp/tracking_frame_{frame_idx}_result.jpg"
        cv2.imwrite(output_path, annotated_frame)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    cap.release()
    print("\nâœ… í”„ë ˆì„ë³„ ì¶”ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    video_path = "data/people.mp4"

    if not Path(video_path).exists():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        print("ğŸ“ data ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤:")
        for f in Path("data").glob("*.mp4"):
            print(f"   {f}")
        exit(1)

    print("ğŸš€ OC-SORT ì¶”ì  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (5í”„ë ˆì„ ì—°ì†)")
    print("=" * 50)

    # temp ë””ë ‰í† ë¦¬ ìƒì„±
    Path("temp").mkdir(exist_ok=True)

    # 1. íŠ¹ì • í”„ë ˆì„ë“¤ì—ì„œ ì¶”ì  í…ŒìŠ¤íŠ¸
    print("\nğŸ“Š ì—°ì† í”„ë ˆì„ ì¶”ì  í…ŒìŠ¤íŠ¸ (50-54)")
    test_tracking_on_video_frames(video_path, [50, 51, 52, 53, 54])

    print("\nğŸ¯ ê²°ë¡ :")
    print("1. temp/tracking_frame_*.jpg íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”")
    print("2. ì´ì œ ëª¨ë“  detectionì´ Track IDë¥¼ ê°€ì§‘ë‹ˆë‹¤!")
    print("3. ë” ì´ìƒ '?' í‘œì‹œê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

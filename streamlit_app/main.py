"""
2D Access Control MVP - Streamlit ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

OC-SORT ê¸°ë°˜ ë¼ì¸ í¬ë¡œì‹± ì¶”ì  ì‹œìŠ¤í…œ
"""

import os
import sys
import tempfile
import time
from pathlib import Path
from typing import Optional

import cv2
import numpy as np
import streamlit as st

# macOS ì¹´ë©”ë¼ ê¶Œí•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENCV_AVFOUNDATION_SKIP_AUTH"] = "1"

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.core.models import DetectionResult
from src.tracking.engine import ObjectTracker
from src.video.source import VideoSource

# ì„¤ì •
st.set_page_config(
    page_title="2D Access Control System",
    page_icon="ğŸšª",
    layout="wide",
    initial_sidebar_state="expanded",
)


class StreamlitApp:
    """Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ í´ë˜ìŠ¤"""

    def __init__(self):
        self.tracker = None
        self.video_source = None
        self.is_running = False
        self.frame_count = 0
        self.detection_count = 0
        self.crossing_count = 0

    def initialize_tracker(self, confidence_threshold: float):
        """íŠ¸ë˜ì»¤ ì´ˆê¸°í™”"""
        try:
            self.tracker = ObjectTracker(det_thresh=confidence_threshold)
            st.success("íŠ¸ë˜ì»¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
        except Exception as e:
            st.error(f"íŠ¸ë˜ì»¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def process_video_file(self, uploaded_file, confidence_threshold: float):
        """ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬"""
        if uploaded_file is not None:
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(
                    delete=False, suffix=".mp4"
                ) as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_file_path = tmp_file.name

                # VideoSourceë¡œ ë¹„ë””ì˜¤ ì—´ê¸°
                self.video_source = VideoSource()
                if self.video_source.open(tmp_file_path):
                    frame_count = self.video_source.get_frame_count()
                    fps = self.video_source.get_fps()
                    st.success(
                        f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ {frame_count}í”„ë ˆì„, {fps:.1f} FPS)"
                    )
                    return True
                else:
                    st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return False
            except Exception as e:
                st.error(f"ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                return False
        return False

    def process_camera(self, camera_id: int):
        """ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬"""
        try:
            self.video_source = VideoSource()
            if self.video_source.open(camera_id):
                st.success(f"ì¹´ë©”ë¼ {camera_id}ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
                return True
            else:
                st.error(
                    f"ì¹´ë©”ë¼ {camera_id}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´ë©”ë¼ IDë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
                )
                st.info(
                    "ğŸ’¡ macOSì—ì„œëŠ” ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ í™˜ê²½ì„¤ì • > ë³´ì•ˆ ë° ê°œì¸ì •ë³´ë³´í˜¸ > ì¹´ë©”ë¼ì—ì„œ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                )
                return False
        except Exception as e:
            st.error(f"ì¹´ë©”ë¼ ì—°ê²° ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def draw_detections(self, frame: np.ndarray, detections: list) -> np.ndarray:
        """í”„ë ˆì„ì— ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°"""
        for detection in detections:
            x, y, w, h = detection.bbox
            track_id = detection.track_id
            confidence = detection.confidence
            class_name = detection.class_name

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            color = (0, 255, 0) if track_id > 0 else (0, 0, 255)
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)

            # íŠ¸ë™ IDì™€ ì •ë³´ í‘œì‹œ
            label = f"ID:{track_id} {class_name} {confidence:.2f}"
            cv2.putText(
                frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
            )

            # ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸°
            center_x, center_y = detection.center_point
            cv2.circle(frame, (int(center_x), int(center_y)), 3, color, -1)

        return frame

    def run_tracking(self, video_placeholder, stats_placeholder, events_placeholder):
        """íŠ¸ë˜í‚¹ ì‹¤í–‰"""
        if self.video_source is None or self.tracker is None:
            st.error("ë¹„ë””ì˜¤ ì†ŒìŠ¤ì™€ íŠ¸ë˜ì»¤ë¥¼ ë¨¼ì € ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
            return

        self.frame_count = 0
        self.detection_count = 0

        try:
            while self.is_running:
                success, frame = self.video_source.read_frame()

                if not success:
                    st.warning("ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    self.is_running = False
                    break

                # íŠ¸ë˜í‚¹ ìˆ˜í–‰
                tracking_frame = self.tracker.track_frame(frame)

                # ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
                annotated_frame = self.draw_detections(
                    frame.copy(), tracking_frame.detections
                )

                # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
                cv2.putText(
                    annotated_frame,
                    f"Frame: {self.frame_count}",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (255, 255, 255),
                    2,
                )

                # ë¹„ë””ì˜¤ í‘œì‹œ (deprecated íŒŒë¼ë¯¸í„° ìˆ˜ì •)
                video_placeholder.image(
                    annotated_frame, channels="BGR", use_container_width=True
                )

                # í†µê³„ ì—…ë°ì´íŠ¸
                self.frame_count += 1
                self.detection_count += len(tracking_frame.detections)

                # í†µê³„ í‘œì‹œ
                with stats_placeholder.container():
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í”„ë ˆì„", self.frame_count)
                    with col2:
                        st.metric("ì´ ê°ì§€", self.detection_count)
                    with col3:
                        st.metric("ë¼ì¸ êµì°¨", self.crossing_count)

                # ì´ë²¤íŠ¸ í‘œì‹œ
                if tracking_frame.detections:
                    with events_placeholder.container():
                        st.write("**ìµœê·¼ ê°ì§€ëœ ê°ì²´ë“¤:**")
                        for det in tracking_frame.detections[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                            st.write(
                                f"- ID {det.track_id}: {det.class_name} (ì‹ ë¢°ë„: {det.confidence:.2f})"
                            )

                # í”„ë ˆì„ ë ˆì´íŠ¸ ì¡°ì ˆ
                time.sleep(0.03)  # ì•½ 30 FPS

        except Exception as e:
            st.error(f"íŠ¸ë˜í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.is_running = False

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.is_running = False
        if self.video_source:
            self.video_source.release()
            self.video_source = None


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.title("ğŸšª 2D Access Control MVP")
    st.markdown("**OC-SORT ê¸°ë°˜ ê°ì²´ ì¶”ì  ë° ë¼ì¸ í¬ë¡œì‹± ê°ì§€ ì‹œìŠ¤í…œ**")
    st.markdown("---")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "app" not in st.session_state:
        st.session_state.app = StreamlitApp()

    app = st.session_state.app

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ë¹„ë””ì˜¤ ì†ŒìŠ¤ ì„ íƒ
        video_source_type = st.selectbox(
            "ë¹„ë””ì˜¤ ì†ŒìŠ¤ ì„ íƒ",
            ["ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼", "ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"],
            index=1,  # ê¸°ë³¸ê°’ì„ íŒŒì¼ ì—…ë¡œë“œë¡œ ë³€ê²½
        )

        st.markdown("---")

        # ì¶”ì  ì„¤ì •
        st.subheader("ğŸ¯ ì¶”ì  ì„¤ì •")
        confidence_threshold = st.slider("ì‹ ë¢°ë„ ì„ê³„ê°’", 0.1, 1.0, 0.6, 0.1)

        # íŠ¸ë˜ì»¤ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”§ íŠ¸ë˜ì»¤ ì´ˆê¸°í™”"):
            app.initialize_tracker(confidence_threshold)

        st.markdown("---")

        # ë¹„ë””ì˜¤ ì†ŒìŠ¤ë³„ ì„¤ì •
        if video_source_type == "ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼":
            st.subheader("ğŸ“¹ ì¹´ë©”ë¼ ì„¤ì •")
            camera_id = st.number_input("ì¹´ë©”ë¼ ID", min_value=0, max_value=10, value=0)

            st.info("ğŸ’¡ macOSì—ì„œëŠ” í„°ë¯¸ë„ì— ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            if st.button("ğŸ“¹ ì¹´ë©”ë¼ ì—°ê²°"):
                app.process_camera(camera_id)

        else:  # ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
            st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ",
                type=["mp4", "avi", "mov", "mkv"],
                help="MP4, AVI, MOV, MKV í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.",
            )

            if uploaded_file is not None:
                if st.button("ğŸ“ íŒŒì¼ ë¡œë“œ"):
                    app.process_video_file(uploaded_file, confidence_threshold)

        st.markdown("---")

        # ì œì–´ ë²„íŠ¼
        st.subheader("ğŸ® ì œì–´")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("â–¶ï¸ ì‹œì‘", use_container_width=True):
                if app.video_source and app.tracker:
                    app.is_running = True
                    st.success("ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
                else:
                    st.error("ë¹„ë””ì˜¤ ì†ŒìŠ¤ì™€ íŠ¸ë˜ì»¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.")

        with col2:
            if st.button("â¹ï¸ ì •ì§€", use_container_width=True):
                app.is_running = False
                st.info("ì¶”ì ì´ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if st.button("ğŸ”„ ë¦¬ì…‹", use_container_width=True):
            app.cleanup()
            st.session_state.app = StreamlitApp()
            st.success("ì‹œìŠ¤í…œì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ“¹ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
        video_placeholder = st.empty()

        # ê¸°ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        if not app.is_running:
            dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(
                dummy_frame,
                "Video Stream Ready...",
                (150, 240),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (255, 255, 255),
                2,
            )
            video_placeholder.image(
                dummy_frame, channels="BGR", use_container_width=True
            )

    with col2:
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í†µê³„")
        stats_placeholder = st.empty()

        # ê¸°ë³¸ í†µê³„ í‘œì‹œ
        with stats_placeholder.container():
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í”„ë ˆì„", app.frame_count)
            with col2:
                st.metric("ì´ ê°ì§€", app.detection_count)
            with col3:
                st.metric("ë¼ì¸ êµì°¨", app.crossing_count)

        st.markdown("---")

        st.subheader("ğŸ”” ìµœê·¼ ì´ë²¤íŠ¸")
        events_placeholder = st.empty()

        with events_placeholder.container():
            st.info("ì¶”ì ì„ ì‹œì‘í•˜ë©´ ì´ë²¤íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    # ì¶”ì  ì‹¤í–‰
    if app.is_running:
        app.run_tracking(video_placeholder, stats_placeholder, events_placeholder)


if __name__ == "__main__":
    main()
